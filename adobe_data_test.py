import pandas as pd
import numpy as np
import re
import datetime
import boto3
from io import StringIO 
pd.options.mode.chained_assignment = None

class Searchrevenue:

    def engine_key_revenue_generator(input_file):
        
        # Fetch source data from S3 (Raw Zone)
        s3_client = boto3.client('s3')
        input_file="raw_zone/"+input_file
        resp = s3_client.get_object(Bucket="adobedatatest",Key=input_file)
        src_df = pd.read_csv(resp['Body'], delimiter="\t")
    
        # Picking only the columns of interest
        src_df=src_df[['event_list','product_list','referrer']]

        # Querying Search Engine Domain Names from 'referrer' column into a new column
        src_df['Search Engine Domain']=src_df['referrer'].str.split('.').str[1].str.title()

        # Querying Search Keywords from 'referrer' column into a new column
        kw_chars=['?q=','&q=','?p=','&p=','?k=','&k=']
        kw_chars_reg_remove=[re.escape(i) for i in kw_chars]
        con=src_df['referrer'].str.split('|'.join(kw_chars_reg_remove)).str[1]
        src_df['Search Keyword']=np.where(con.str.contains('&'),con.str.split('&').str[0],con)
        src_df['Search Keyword']=src_df['Search Keyword'].str.split('+')
        src_df=src_df.explode('Search Keyword')
        src_df['Search Keyword']=src_df['Search Keyword'].str.title()
    
        # Unique combinations of all SearchEngine-Keywords into a new dataframe
        uniq_sea_eng_key_df=src_df[['Search Engine Domain','Search Keyword']].drop_duplicates()
        uniq_sea_eng_key_df=uniq_sea_eng_key_df[~uniq_sea_eng_key_df['Search Keyword'].isnull()]
    
        # Revenues generated by different SearchEngine-Keywords into a new dataframe
        rev_per_eng_key_df=src_df.loc[src_df['event_list']==1,['product_list','Search Engine Domain']]
        rev_per_eng_key_df['Revenue']=rev_per_eng_key_df['product_list'].str.split(';').str[3].astype(int)
        rev_per_eng_key_df['Search Keyword']=rev_per_eng_key_df['product_list'].str.split(';').str[1].str.split(' - ').str[0]
        del rev_per_eng_key_df['product_list']

        # Merging revenue generated dataframe with all possible unique combinations of SearchEngine-Keyword and ordering in descending order of revenue
        master_df=pd.merge(uniq_sea_eng_key_df,rev_per_eng_key_df,how='left')
        master_df=master_df.groupby(['Search Engine Domain','Search Keyword']).sum().reset_index().sort_values(by=['Revenue','Search Engine Domain','Search Keyword'],ascending=[False,True,True])
        
        # Exporting results generated on a specific day to another S3 bucket (refined_zone_result)
        csv_buffer = StringIO()
        master_df.to_csv(csv_buffer,index=False,sep="\t")
        s3_resource = boto3.resource('s3')
        s3_resource.Object('adobedatatest','refined_zone_result/'+datetime.datetime.today().strftime('%Y-%m-%d')+'_SearchKeywordPerformance.tab').put(Body=csv_buffer.getvalue())
        
        print(master_df)

def lambda_handler(event,context):
    Searchrevenue.engine_key_revenue_generator('data.txt')